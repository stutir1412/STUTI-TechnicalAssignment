{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stutir1412/STUTI-TechnicalAssignment/blob/main/Task_3_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3: NLP Training"
      ],
      "metadata": {
        "id": "grlxBCOqqJq3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_qYbQ6u8puv",
        "outputId": "a1765f8a-4523-4712-ed18-f2ebb812260d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To first download the dataset from the provided link"
      ],
      "metadata": {
        "id": "FMoAlSYfqTyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVhBSac88yob",
        "outputId": "0f20776f-ca5c-4882-c90d-ace7e0f4b870"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 00:01:55--  https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio\n",
            "Resolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\n",
            "Connecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 759757 (742K)\n",
            "Saving to: ‘restauranttrain.bio.1’\n",
            "\n",
            "restauranttrain.bio 100%[===================>] 741.95K  1.24MB/s    in 0.6s    \n",
            "\n",
            "2023-11-21 00:01:56 (1.24 MB/s) - ‘restauranttrain.bio.1’ saved [759757/759757]\n",
            "\n",
            "--2023-11-21 00:01:56--  https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio\n",
            "Resolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\n",
            "Connecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155722 (152K)\n",
            "Saving to: ‘restauranttest.bio.1’\n",
            "\n",
            "restauranttest.bio. 100%[===================>] 152.07K   455KB/s    in 0.3s    \n",
            "\n",
            "2023-11-21 00:01:57 (455 KB/s) - ‘restauranttest.bio.1’ saved [155722/155722]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing Dataset"
      ],
      "metadata": {
        "id": "GFfbIlbMqapu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reverse the tag and the column column in both the test and train files.\n",
        "\n",
        "- Replace the tab seperator to space.\n",
        "\n",
        "- Change the example seperator to newline"
      ],
      "metadata": {
        "id": "jTqZZ-xIrfWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the content of the 'restauranttrain.bio' file to a new file 'train.txt'\n",
        "# by swapping the first and second columns and saving it to the specified path.\n",
        "\n",
        "!awk '{print $2,$1}' restauranttest.bio > \"/content/drive/My Drive/WalnutAI/test.txt\"\n",
        "!awk '{print $2,$1}' restauranttrain.bio > \"/content/drive/My Drive/WalnutAI/train.txt\"\n",
        "\n",
        "# Replace all tab characters ('\\t') with a space (' ') in the 'test.txt' file.\n",
        "!sed -i 's/\\t/ /g' '/content/drive/My Drive/WalnutAI/test.txt'\n",
        "\n",
        "# Replace the beginning of a line followed by a space ('^ $') with a newline character ('\\n')\n",
        "# in the 'test.txt' file. This is intended to handle empty lines.\n",
        "!sed -i 's/^ $/\\n/g' '/content/drive/My Drive/WalnutAI/test.txt'\n",
        "\n",
        "# Replace all tab characters ('\\t') with a space (' ') in the 'train.txt' file.\n",
        "!sed -i 's/\\t/ /g' '/content/drive/My Drive/WalnutAI/train.txt'\n",
        "\n",
        "# Replace the beginning of a line followed by a space ('^ $') with a newline character ('\\n')\n",
        "# in the 'train.txt' file. This is intended to handle empty lines.\n",
        "!sed -i 's/^ $/\\n/g' '/content/drive/My Drive/WalnutAI/train.txt'"
      ],
      "metadata": {
        "id": "EU4NHPn_8zQu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/My Drive/WalnutAI/train.txt',sep=' ', header=None)"
      ],
      "metadata": {
        "id": "oUmuu3JH84Y2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a labels document"
      ],
      "metadata": {
        "id": "WnS6d9VHryUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/WalnutAI/labels.txt','w') as fout:\n",
        "  for tag in df[1].unique():\n",
        "    fout.write(tag+'\\n')"
      ],
      "metadata": {
        "id": "36KZdh1087Av"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Spacy NLP Libraray"
      ],
      "metadata": {
        "id": "j3Sqmcdcr4xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install spaCy and download a spaCy model\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFcQrM_Q9_RH",
        "outputId": "0eb994ba-b8e3-45ad-d2a1-9a86a1326320"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2023-11-21 00:02:12.316967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-21 00:02:12.317027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-21 00:02:12.317063: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-21 00:02:12.325380: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-21 00:02:13.447937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-21 00:02:14.924452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 00:02:14.924905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-21 00:02:14.925092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import random\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Load training data\n",
        "with open('/content/drive/My Drive/WalnutAI/train.txt') as f:\n",
        "    training_data = f.readlines()\n",
        "\n",
        "# Load the labels\n",
        "with open('/content/drive/My Drive/WalnutAI/labels.txt') as label_file:\n",
        "    labels = label_file.read().splitlines()\n",
        "\n",
        "# Add labels to the NER component\n",
        "ner = nlp.get_pipe('ner')\n",
        "for label in labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "# Define the training loop\n",
        "def train_spacy_ner(training_data, iterations=5):\n",
        "    # Train the model for a given number of iterations\n",
        "    for epoch in range(iterations):\n",
        "        random.shuffle(training_data)\n",
        "        losses ={}\n",
        "        for line in training_data:\n",
        "            parts = line.split()\n",
        "            if len(parts) > 1:\n",
        "                text = parts[1:]\n",
        "                entities = []\n",
        "                start = 0\n",
        "                for word in text:\n",
        "                    entities.append((start, start + len(word), parts[0]))\n",
        "                    start += len(word) + 1\n",
        "                example = Example.from_dict(nlp.make_doc(' '.join(text)), {\"entities\": entities})\n",
        "                ner.update([example], drop=0.5, losses=losses )\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{iterations} - Losses: {losses[\"ner\"]}')\n",
        "\n",
        "    return nlp\n",
        "\n",
        "# Train the NER model\n",
        "trained_nlp = train_spacy_ner(training_data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ5XVP6D8-XZ",
        "outputId": "28b1e4e2-a796-456c-c17b-ef0a066df41f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Losses: 106076.41537637149\n",
            "Epoch 2/5 - Losses: 103432.16096246311\n",
            "Epoch 3/5 - Losses: 103597.24967763793\n",
            "Epoch 4/5 - Losses: 103589.07117387516\n",
            "Epoch 5/5 - Losses: 103326.35299982602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Save the Trained Model"
      ],
      "metadata": {
        "id": "nNF8ibvPsGtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_nlp.to_disk('/content/drive/My Drive/WalnutAI/ner_model')"
      ],
      "metadata": {
        "id": "LDggK0l1_0cp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the model"
      ],
      "metadata": {
        "id": "8h_Ca_3Ynnny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_nlp = spacy.load('/content/drive/My Drive/WalnutAI/ner_model')\n",
        "\n",
        "# Test the model with a sample text\n",
        "text = \"any 50s style diners around\" #Type input text here\n",
        "doc = loaded_nlp(text)\n",
        "\n",
        "# Extract named entities and their labels in dictionary format\n",
        "named_entities = {ent.text: ent.label_ for ent in doc.ents}\n",
        "print(named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qSXUS9xlbgC",
        "outputId": "48b2bfc9-49a6-422c-8a2b-e4f4c9063e8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'50s': 'CARDINAL'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, after testing with 3 sentences, I observed that my named entity recognition model accuracy is really poor which is why it gives out wrong output enitity. I believe by adopting the following techniques the model can improve\n",
        "- To train it for more number of iterations (around 20) to allow the model have more exposure to the training data. Currently, due to the large dataset I could only train for 5 epoch as it took extremely long time. Additionly, running on GPU can help improve training time.\n",
        "- Dropout rate can be adjusted to lower it to around 0.3. A higher dropout rate can help prevent overfitting, but it might slow down convergence.\n",
        "- Experiment with different spaCy model architectures or use a larger pre-trained model for better performance. Such as - using en_core_web_md or en_core_web_lg instead of en_core_web_sm.\n"
      ],
      "metadata": {
        "id": "CXjdZOKgnx70"
      }
    }
  ]
}